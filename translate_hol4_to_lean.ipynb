{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b382f1bb",
   "metadata": {},
   "source": [
    "# HOL4 to LEAN Translation using Gemini API\n",
    "\n",
    "This notebook translates HOL4 theorem statements to LEAN using Google's Gemini API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff130e",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "258f0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in e:\\anaconda\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in e:\\anaconda\\lib\\site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in e:\\anaconda\\lib\\site-packages (from google-generativeai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in e:\\anaconda\\lib\\site-packages (from google-generativeai) (2.137.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in e:\\anaconda\\lib\\site-packages (from google-generativeai) (2.32.0)\n",
      "Requirement already satisfied: protobuf in e:\\anaconda\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in e:\\anaconda\\lib\\site-packages (from google-generativeai) (1.10.12)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\lib\\site-packages (from google-generativeai) (4.11.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in e:\\anaconda\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in e:\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in e:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in e:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.2)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in e:\\anaconda\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in e:\\anaconda\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in e:\\anaconda\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in e:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in e:\\anaconda\\lib\\site-packages (from google-api-core->google-generativeai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in e:\\anaconda\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c917cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9402298a",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your Gemini API key here. You can get one from: https://makersuite.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "122cc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef61e99",
   "metadata": {},
   "source": [
    "## File Paths Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "270c35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "INPUT_FILE = \"extracted/output.json\"\n",
    "OUTPUT_FILE = \"extracted/output_lean.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa382d6c",
   "metadata": {},
   "source": [
    "## Initialize Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2364ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = genai.GenerativeModel('gemini-2.5-pro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10586281",
   "metadata": {},
   "source": [
    "## Translation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea346883",
   "metadata": {},
   "source": [
    "### Translation Strategy\n",
    "\n",
    "This notebook now uses a **batch translation approach** where all statements are sent to the LLM at once. This has several advantages:\n",
    "\n",
    "1. **Dependency Awareness**: The LLM can see all Datatypes, Definitions, and Theorems together, understanding how they relate to each other.\n",
    "\n",
    "2. **Type Consistency**: When translating theorems that reference datatypes or definitions, the LLM knows exactly how those types were translated.\n",
    "\n",
    "3. **Efficiency**: Only one API call is needed instead of multiple calls (though this may hit token limits for very large files).\n",
    "\n",
    "4. **Ordering**: Statements are sorted during extraction (Datatypes → Definitions → Theorems) to ensure dependencies are presented in the correct order.\n",
    "\n",
    "**Note**: For very large files (>100 items), you may need to split them into chunks to avoid token limits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34c5108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_all_statements(data: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Translate all HOL4 statements to LEAN in one API call, considering dependencies.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries with 'kind', 'name', and 'statement' fields\n",
    "    \n",
    "    Returns:\n",
    "        List of translated items with LEAN statements\n",
    "    \"\"\"\n",
    "    # Input data is already sorted (Datatypes → Definitions → Theorems)\n",
    "    # No need to sort again\n",
    "    \n",
    "    # Build the prompt with all statements\n",
    "    prompt = \"\"\"You are an expert in formal theorem proving systems. Translate ALL of the following HOL4 statements to LEAN 4 syntax.\n",
    "\n",
    "IMPORTANT: The statements are ordered by dependency - Datatypes first, then Definitions, then Theorems. Many theorems and definitions depend on the datatypes and earlier definitions. Please consider these dependencies when translating.\n",
    "\n",
    "Instructions:\n",
    "- Use LEAN 4 syntax (not LEAN 3)\n",
    "- Preserve the logical structure and meaning\n",
    "- Use appropriate LEAN type annotations\n",
    "- Handle option types (SOME/NONE in HOL4 → some/none in LEAN)\n",
    "- Convert HOL4 list notation to LEAN list notation\n",
    "- Use LEAN's unicode symbols where appropriate (e.g., ∀, ∃, →, ∧, ∨)\n",
    "- Pay attention to type definitions (Datatypes) as later statements may reference them\n",
    "- Ensure definitions are properly typed based on earlier type definitions\n",
    "- When a theorem references a datatype or definition above, reuse the exact translated identifier and signature from that earlier translation\n",
    "\n",
    "Format your response as a JSON array where each element has:\n",
    "{\n",
    "  \"name\": \"original_name\",\n",
    "  \"statement\": \"translated LEAN 4 statement\"\n",
    "}\n",
    "\n",
    "Here are the HOL4 statements to translate:\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add all statements to the prompt (using original order)\n",
    "    for i, item in enumerate(data, 1):\n",
    "        prompt += f\"\\n{i}. {item['kind']}: {item['name']}\\n\"\n",
    "        prompt += f\"   HOL4 Statement:\\n   {item['statement']}\\n\"\n",
    "    \n",
    "    prompt += \"\\n\\nPlease provide the translations as a JSON array. Include ONLY the JSON array in your response, no additional text or markdown.\"\n",
    "    \n",
    "    try:\n",
    "        print(\"Sending all statements to LLM for translation...\")\n",
    "        response = model.generate_content(prompt)\n",
    "        response_text = response.text.strip()\n",
    "        \n",
    "        # Clean up markdown formatting if present\n",
    "        if response_text.startswith(\"```json\"):\n",
    "            response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        elif response_text.startswith(\"```\"):\n",
    "            lines = response_text.split(\"\\n\")\n",
    "            response_text = \"\\n\".join(lines[1:-1]).strip()\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        translated_items = json.loads(response_text)\n",
    "        \n",
    "        # Match translations back to original items (preserving original order)\n",
    "        name_to_translation = {item['name']: item['statement'] for item in translated_items}\n",
    "        \n",
    "        result = []\n",
    "        for item in data:  # Use original order\n",
    "            lean_statement = name_to_translation.get(item['name'], f\"[Translation not found for {item['name']}]\")\n",
    "            translated_item = {\n",
    "                \"kind\": item['kind'],\n",
    "                \"name\": item['name'],\n",
    "                \"statement\": lean_statement,\n",
    "                \"original_hol4\": item['statement']\n",
    "            }\n",
    "            if 'source_file' in item:\n",
    "                translated_item['source_file'] = item['source_file']\n",
    "            result.append(translated_item)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON response: {str(e)}\")\n",
    "        print(f\"Response text: {response_text[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdeb5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_json_file_chunked(input_path: str, output_path: str, chunk_size: int = 50) -> None:\n",
    "    \"\"\"\n",
    "    Translate statements in chunks for large files.\n",
    "    Useful when the file is too large to process in one API call.\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input JSON file\n",
    "        output_path: Path to output JSON file\n",
    "        chunk_size: Number of items to process per chunk\n",
    "    \"\"\"\n",
    "    # Load the input JSON file\n",
    "    print(f\"Loading input file: {input_path}\")\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"Found {len(data)} items to translate\")\n",
    "    \n",
    "    # Input data is already sorted by dependency order (Datatypes → Definitions → Theorems)\n",
    "    # No need to sort again\n",
    "    \n",
    "    # Split into chunks\n",
    "    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "    print(f\"Processing in {len(chunks)} chunks of up to {chunk_size} items each\")\n",
    "    \n",
    "    all_translated = []\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"\\nProcessing chunk {i}/{len(chunks)} ({len(chunk)} items)...\")\n",
    "        translated_chunk = translate_all_statements(chunk)\n",
    "        all_translated.extend(translated_chunk)\n",
    "        \n",
    "        # Small delay between chunks\n",
    "        if i < len(chunks):\n",
    "            time.sleep(2)\n",
    "    \n",
    "    # No need to restore original order since we preserved it throughout\n",
    "    \n",
    "    # Save the translated data\n",
    "    print(f\"\\nSaving translated data to: {output_path}\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_translated, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nTranslation complete! {len(all_translated)} items translated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4c972",
   "metadata": {},
   "source": [
    "## Test Translation on a Single Example\n",
    "\n",
    "Let's test the translation on one theorem first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "641282e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 items\n",
      "  Datatypes: 21\n",
      "  Definitions: 27\n",
      "  Theorems: 53\n",
      "\n",
      "Testing translation on first 5 items...\n",
      "Sending all statements to LLM for translation...\n",
      "\n",
      "Translation Results:\n",
      "================================================================================\n",
      "Starting full translation...\n",
      "Loading input file: extracted/output.json\n",
      "Found 101 items to translate\n",
      "  Datatypes: 21\n",
      "  Definitions: 27\n",
      "  Theorems: 53\n",
      "Sending all statements to LLM for translation...\n",
      "\n",
      "Saving translated data to: extracted/output_lean.json\n",
      "\n",
      "Translation complete! 101 items translated.\n",
      "Full translation completed!\n",
      "\n",
      "Datatype: lit\n",
      "HOL4: lit =\n",
      "    IntLit int\n",
      "  | Char char\n",
      "  | StrLit string\n",
      "  | Word8 word8\n",
      "  | Word64 word64\n",
      "  | Float64 w...\n",
      "LEAN: inductive Lit where\n",
      "  | intLit : Int → Lit\n",
      "  | charLit : Char → Lit\n",
      "  | strLit : String → Lit\n",
      "  | wo...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Datatype: opn\n",
      "HOL4: opn = Plus | Minus | Times | Divide | Modulo\n",
      "LEAN: inductive Opn where\n",
      "  | plus\n",
      "  | minus\n",
      "  | times\n",
      "  | divide\n",
      "  | modulo\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Datatype: opb\n",
      "HOL4: opb = Lt | Gt | Leq | Geq\n",
      "LEAN: inductive Opb where\n",
      "  | lt\n",
      "  | gt\n",
      "  | leq\n",
      "  | geq\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Datatype: opw\n",
      "HOL4: opw = Andw | Orw | Xor | Add | Sub\n",
      "LEAN: inductive Opw where\n",
      "  | andw\n",
      "  | orw\n",
      "  | xor\n",
      "  | add\n",
      "  | sub\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Datatype: shift\n",
      "HOL4: shift = Lsl | Lsr | Asr | Ror\n",
      "LEAN: inductive Shift where\n",
      "  | lsl\n",
      "  | lsr\n",
      "  | asr\n",
      "  | ror\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load a sample from the input file\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(sample_data)} items\")\n",
    "print(f\"  Datatypes: {sum(1 for x in sample_data if x['kind'] == 'Datatype')}\")\n",
    "print(f\"  Definitions: {sum(1 for x in sample_data if x['kind'] == 'Definition')}\")\n",
    "print(f\"  Theorems: {sum(1 for x in sample_data if x['kind'] == 'Theorem')}\")\n",
    "\n",
    "# Test translation on a small subset (first 5 items)\n",
    "test_sample = sample_data[:5]\n",
    "print(f\"\\nTesting translation on first {len(test_sample)} items...\")\n",
    "\n",
    "translated_sample = translate_all_statements(test_sample)\n",
    "\n",
    "print(f\"\\nTranslation Results:\")\n",
    "print(\"=\"*80)## Run Full Translation\n",
    "\n",
    "# Choose one of the following approaches based on your file size:\n",
    "\n",
    "# Option 1: Translate all at once (recommended for files with < 100 items)\n",
    "print(\"Starting full translation...\")\n",
    "translate_json_file(INPUT_FILE, OUTPUT_FILE)\n",
    "\n",
    "# Option 2: Use chunked translation for larger files (uncomment if needed)\n",
    "# print(\"Starting chunked translation...\")\n",
    "# translate_json_file_chunked(INPUT_FILE, OUTPUT_FILE, chunk_size=50)\n",
    "\n",
    "print(\"Full translation completed!\")\n",
    "for item in translated_sample:\n",
    "    print(f\"\\n{item['kind']}: {item['name']}\")\n",
    "    print(f\"HOL4: {item['original_hol4'][:100]}...\" if len(item['original_hol4']) > 100 else f\"HOL4: {item['original_hol4']}\")\n",
    "    print(f\"LEAN: {item['statement'][:100]}...\" if len(item['statement']) > 100 else f\"LEAN: {item['statement']}\")\n",
    "    print(\"-\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97e90995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full translation...\n",
      "Loading input file: extracted/output.json\n",
      "Found 101 items to translate\n",
      "  Datatypes: 21\n",
      "  Definitions: 27\n",
      "  Theorems: 53\n",
      "Sending all statements to LLM for translation...\n",
      "\n",
      "Saving translated data to: extracted/output_lean.json\n",
      "\n",
      "Translation complete! 101 items translated.\n",
      "Full translation completed!\n"
     ]
    }
   ],
   "source": [
    "## Run Full Translation\n",
    "\n",
    "# Choose one of the following approaches based on your file size:\n",
    "\n",
    "# Option 1: Translate all at once (recommended for files with < 100 items)\n",
    "print(\"Starting full translation...\")\n",
    "translate_json_file(INPUT_FILE, OUTPUT_FILE)\n",
    "\n",
    "# Option 2: Use chunked translation for larger files (uncomment if needed)\n",
    "# print(\"Starting chunked translation...\")\n",
    "# translate_json_file_chunked(INPUT_FILE, OUTPUT_FILE, chunk_size=50)\n",
    "\n",
    "print(\"Full translation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634b4ea",
   "metadata": {},
   "source": [
    "## Export Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b958c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Statistics:\n",
      "==================================================\n",
      "Total items translated: 101\n",
      "\n",
      "Breakdown by kind:\n",
      "  Datatype: 21\n",
      "  Definition: 27\n",
      "  Theorem: 53\n",
      "\n",
      "Translation errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Generate statistics about the translation\n",
    "with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    translated_data = json.load(f)\n",
    "\n",
    "print(\"Translation Statistics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total items translated: {len(translated_data)}\")\n",
    "\n",
    "# Count by kind\n",
    "kind_counts = {}\n",
    "for item in translated_data:\n",
    "    kind = item['kind']\n",
    "    kind_counts[kind] = kind_counts.get(kind, 0) + 1\n",
    "\n",
    "print(\"\\nBreakdown by kind:\")\n",
    "for kind, count in kind_counts.items():\n",
    "    print(f\"  {kind}: {count}\")\n",
    "\n",
    "# Check for translation errors\n",
    "errors = [item for item in translated_data if \"[Translation Error\" in item['statement']]\n",
    "print(f\"\\nTranslation errors: {len(errors)}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nItems with errors:\")\n",
    "    for item in errors:\n",
    "        print(f\"  - {item['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c63565",
   "metadata": {},
   "source": [
    "## Check Dependency Awareness\n",
    "\n",
    "Let's verify that the translation properly handles dependencies between Datatypes, Definitions, and Theorems:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8d35d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Chain Example:\n",
      "================================================================================\n",
      "\n",
      "1. DATATYPE (defines types used by definitions and theorems):\n",
      "   Name: lit\n",
      "   HOL4: lit =\n",
      "    IntLit int\n",
      "  | Char char\n",
      "  | StrLit string\n",
      "  | Word8 word8\n",
      "  | Word64 ...\n",
      "   LEAN: inductive lit where\n",
      "  | IntLit (i : Int) : lit\n",
      "  | Char (c : Char) : lit\n",
      "  | Str...\n",
      "\n",
      "2. DEFINITION (may use datatypes, used by theorems):\n",
      "   Name: isFpBool_def\n",
      "   HOL4: isFpBool op = case op of FP_cmp _ => T | _ => F...\n",
      "   LEAN: def isFpBool (o : op) : Bool :=\n",
      "  match o with\n",
      "  | op.FP_cmp _ => true\n",
      "  | _ => ...\n",
      "\n",
      "3. THEOREM (may use datatypes and definitions):\n",
      "   Name: mk_id_surj\n",
      "   HOL4: !id. ?p n. id = mk_id p n...\n",
      "   LEAN: theorem mk_id_surj {m n} (i : id m n) : ∃ (p : List m) (val : n), i = mk_id p va...\n"
     ]
    }
   ],
   "source": [
    "# Show examples of how datatypes, definitions, and theorems are related\n",
    "with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "    translated_data = json.load(f)\n",
    "\n",
    "# Find datatypes\n",
    "datatypes = [item for item in translated_data if item['kind'] == 'Datatype']\n",
    "definitions = [item for item in translated_data if item['kind'] == 'Definition']\n",
    "theorems = [item for item in translated_data if item['kind'] == 'Theorem']\n",
    "\n",
    "print(\"Dependency Chain Example:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if datatypes:\n",
    "    print(\"\\n1. DATATYPE (defines types used by definitions and theorems):\")\n",
    "    dt = datatypes[0]\n",
    "    print(f\"   Name: {dt['name']}\")\n",
    "    print(f\"   HOL4: {dt['original_hol4'][:80]}...\")\n",
    "    print(f\"   LEAN: {dt['statement'][:80]}...\")\n",
    "\n",
    "if definitions:\n",
    "    print(\"\\n2. DEFINITION (may use datatypes, used by theorems):\")\n",
    "    defn = definitions[0]\n",
    "    print(f\"   Name: {defn['name']}\")\n",
    "    print(f\"   HOL4: {defn['original_hol4'][:80]}...\")\n",
    "    print(f\"   LEAN: {defn['statement'][:80]}...\")\n",
    "\n",
    "if theorems:\n",
    "    print(\"\\n3. THEOREM (may use datatypes and definitions):\")\n",
    "    thm = theorems[0]\n",
    "    print(f\"   Name: {thm['name']}\")\n",
    "    print(f\"   HOL4: {thm['original_hol4'][:80]}...\")\n",
    "    print(f\"   LEAN: {thm['statement'][:80]}...\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9dc78a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAN file created: extracted/translated_statements.lean\n",
      "Content summary:\n",
      "  - 21 Datatypes\n",
      "  - 27 Definitions\n",
      "  - 53 Theorems (with := sorry)\n"
     ]
    }
   ],
   "source": [
    "## Generate LEAN File\n",
    "\n",
    "# Create a single .lean file with all translated content\n",
    "def create_lean_file(input_json_path: str, output_lean_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a .lean file from the translated JSON data.\n",
    "    \n",
    "    Args:\n",
    "        input_json_path: Path to the translated JSON file\n",
    "        output_lean_path: Path to the output .lean file\n",
    "    \"\"\"\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        translated_data = json.load(f)\n",
    "    \n",
    "    with open(output_lean_path, 'w', encoding='utf-8') as f:\n",
    "        # Write file header\n",
    "        f.write(\"-- Auto-generated LEAN 4 file from HOL4 translation\\n\")\n",
    "        f.write(\"-- Generated using Gemini API\\n\\n\")\n",
    "        \n",
    "        # Process each item in order (already sorted: Datatypes -> Definitions -> Theorems)\n",
    "        for item in translated_data:\n",
    "            kind = item['kind']\n",
    "            name = item['name']\n",
    "            statement = item['statement']\n",
    "            \n",
    "            # Add a comment with the original HOL4 statement\n",
    "            f.write(f\"-- Original HOL4 {kind}: {name}\\n\")\n",
    "            f.write(f\"-- {item['original_hol4']}\\n\")\n",
    "            \n",
    "            if kind == \"Datatype\":\n",
    "                # Write datatype as-is\n",
    "                f.write(f\"{statement}\\n\\n\")\n",
    "                \n",
    "            elif kind == \"Definition\":\n",
    "                # Write definition as-is\n",
    "                f.write(f\"{statement}\\n\\n\")\n",
    "                \n",
    "            elif kind == \"Theorem\":\n",
    "                # Format theorem with := sorry for auto-proving\n",
    "                # Extract theorem name from the statement if possible\n",
    "                if statement.startswith(\"theorem \"):\n",
    "                    # Handle \"theorem name : statement\"\n",
    "                    f.write(f\"{statement} := sorry\\n\\n\")\n",
    "                else:\n",
    "                    # Fallback: assume the statement is just the proposition\n",
    "                    f.write(f\"theorem {name} : {statement} := sorry\\n\\n\")\n",
    "    \n",
    "    print(f\"LEAN file created: {output_lean_path}\")\n",
    "    \n",
    "    # Print statistics\n",
    "    datatypes = sum(1 for x in translated_data if x['kind'] == 'Datatype')\n",
    "    definitions = sum(1 for x in translated_data if x['kind'] == 'Definition')\n",
    "    theorems = sum(1 for x in translated_data if x['kind'] == 'Theorem')\n",
    "    \n",
    "    print(f\"Content summary:\")\n",
    "    print(f\"  - {datatypes} Datatypes\")\n",
    "    print(f\"  - {definitions} Definitions\")\n",
    "    print(f\"  - {theorems} Theorems (with := sorry)\")\n",
    "\n",
    "# Generate the .lean file\n",
    "LEAN_OUTPUT_FILE = \"extracted/translated_statements.lean\"\n",
    "create_lean_file(OUTPUT_FILE, LEAN_OUTPUT_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
