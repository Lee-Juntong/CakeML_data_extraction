{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b382f1bb",
   "metadata": {},
   "source": [
    "# HOL4 to LEAN Translation using Gemini API\n",
    "\n",
    "This notebook translates HOL4 theorem statements to LEAN using Google's Gemini API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff130e",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258f0765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in d:\\anaconda3\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (2.168.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\my-pc\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: protobuf in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (2.11.0)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda3\\lib\\site-packages (from google-generativeai) (4.13.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\my-pc\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\my-pc\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in d:\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c917cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9402298a",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your Gemini API key here. You can get one from: https://makersuite.google.com/app/apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122cc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef61e99",
   "metadata": {},
   "source": [
    "## File Paths Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "270c35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output file paths - processing 4 files in order\n",
    "INPUT_FILES = [\n",
    "    \"extracted/locationScript.json\",\n",
    "    \"extracted/namespaceScript.json\",\n",
    "    \"extracted/astScript.json\", \n",
    "    \"extracted/namespacePropsScript.json\"\n",
    "]\n",
    "\n",
    "OUTPUT_DIR = \"extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56d49799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAN project configuration\n",
    "LEAN_PROJECT_DIR = \"extracted/CML_Lean\"\n",
    "LEAN_SOURCE_DIR = f\"{LEAN_PROJECT_DIR}/CML_Lean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "affa8bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created LEAN package structure at: extracted/CML_Lean/\n",
      "  - lakefile.lean\n",
      "  - lean-toolchain\n",
      "  - Main.lean\n",
      "  - extracted/CML_Lean/CML_Lean/ (source directory)\n"
     ]
    }
   ],
   "source": [
    "## Setup LEAN Package Structure\n",
    "\n",
    "def create_lean_package_structure():\n",
    "    \"\"\"Create the LEAN package directory structure and configuration files.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(LEAN_SOURCE_DIR, exist_ok=True)\n",
    "    \n",
    "    # Create lakefile.lean\n",
    "    lakefile_content = '''import Lake\n",
    "open Lake DSL\n",
    "\n",
    "package «CML_Lean» where\n",
    "  -- add package configuration options here\n",
    "\n",
    "lean_lib «CML_Lean» where\n",
    "  -- add library configuration options here\n",
    "\n",
    "@[default_target]\n",
    "lean_exe «cml_lean» where\n",
    "  root := `Main\n",
    "'''\n",
    "    \n",
    "    with open(f\"{LEAN_PROJECT_DIR}/lakefile.lean\", 'w', encoding='utf-8') as f:\n",
    "        f.write(lakefile_content)\n",
    "    \n",
    "    # Create lean-toolchain file\n",
    "    toolchain_content = 'leanprover/lean4:stable'\n",
    "    with open(f\"{LEAN_PROJECT_DIR}/lean-toolchain\", 'w', encoding='utf-8') as f:\n",
    "        f.write(toolchain_content)\n",
    "    \n",
    "    # Create Main.lean\n",
    "    main_content = '''import «CML_Lean»\n",
    "\n",
    "def main : IO Unit :=\n",
    "  IO.println \"CakeML Translated Theories\"\n",
    "'''\n",
    "    with open(f\"{LEAN_PROJECT_DIR}/Main.lean\", 'w', encoding='utf-8') as f:\n",
    "        f.write(main_content)\n",
    "    \n",
    "    print(f\"Created LEAN package structure at: {LEAN_PROJECT_DIR}/\")\n",
    "    print(f\"  - lakefile.lean\")\n",
    "    print(f\"  - lean-toolchain\")\n",
    "    print(f\"  - Main.lean\")\n",
    "    print(f\"  - {LEAN_SOURCE_DIR}/ (source directory)\")\n",
    "\n",
    "# Create the package structure\n",
    "create_lean_package_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13abbc4",
   "metadata": {},
   "source": [
    "## Important: Building the LEAN Package\n",
    "\n",
    "After generating the LEAN files, you need to:\n",
    "\n",
    "1. **Open the package folder in a NEW VS Code window**: \n",
    "   - Open `extracted/CML_Lean/` as the workspace root (not the current directory)\n",
    "   - This tells LEAN's VS Code extension where to find the package\n",
    "\n",
    "2. **Build the package** (run in terminal inside `extracted/CML_Lean/`):\n",
    "   ```bash\n",
    "   lake build\n",
    "   ```\n",
    "\n",
    "3. **Alternative**: If you want to work from the current workspace, add a `lean-toolchain` file here and configure it to find the package.\n",
    "\n",
    "The error \"unknown module prefix 'CML_Lean'\" occurs because:\n",
    "- LEAN looks for packages relative to the current workspace root\n",
    "- The `lakefile.lean` defines the package, but LEAN needs to know where it is\n",
    "- Opening the package folder directly or building with `lake` resolves this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad68e8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created root module file: extracted/CML_Lean/CML_Lean.lean\n",
      "Imported 4 theory modules:\n",
      "  - ast\n",
      "  - location\n",
      "  - namespace\n",
      "  - namespaceProps\n"
     ]
    }
   ],
   "source": [
    "## Create CML_Lean root module file\n",
    "\n",
    "def create_cml_lean_root_module():\n",
    "    \"\"\"Create the root CML_Lean.lean file that imports all theory modules.\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Get list of all .lean files (theories) in the source directory\n",
    "    theories = []\n",
    "    if os.path.exists(LEAN_SOURCE_DIR):\n",
    "        for filename in sorted(os.listdir(LEAN_SOURCE_DIR)):\n",
    "            if filename.endswith('.lean'):\n",
    "                theory_name = filename.replace('.lean', '')\n",
    "                theories.append(theory_name)\n",
    "    \n",
    "    # Create CML_Lean.lean root file\n",
    "    root_content = f'''-- Root module for CML_Lean package\n",
    "-- This file imports all translated HOL4 theories\n",
    "\n",
    "'''\n",
    "    \n",
    "    for theory in theories:\n",
    "        root_content += f'import CML_Lean.{theory}\\n'\n",
    "    \n",
    "    with open(f\"{LEAN_SOURCE_DIR}.lean\", 'w', encoding='utf-8') as f:\n",
    "        f.write(root_content)\n",
    "    \n",
    "    print(f\"Created root module file: {LEAN_SOURCE_DIR}.lean\")\n",
    "    print(f\"Imported {len(theories)} theory modules:\")\n",
    "    for theory in theories:\n",
    "        print(f\"  - {theory}\")\n",
    "\n",
    "# Create the root module\n",
    "create_cml_lean_root_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359c8741",
   "metadata": {},
   "source": [
    "## Build the LEAN Package\n",
    "\n",
    "**Run the cell below to automatically build the package!**\n",
    "\n",
    "No manual steps needed - the notebook will:\n",
    "1. Run `lake build` in the package directory\n",
    "2. Show you the build output\n",
    "3. Tell you if it succeeded or failed\n",
    "\n",
    "(Alternatively, you can run `lake build` manually in a terminal if you prefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8636fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LEAN package...\n",
      "================================================================================\n",
      "STDOUT:\n",
      "✖ [2/14] Building CML_Lean.namespace (927ms)\n",
      "trace: .> LEAN_PATH=E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\lib\\lean c:\\Users\\my-pc\\.elan\\toolchains\\leanprover--lean4---v4.25.2\\bin\\lean.exe E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\CML_Lean\\namespace.lean -o E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\lib\\lean\\CML_Lean\\namespace.olean -i E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\lib\\lean\\CML_Lean\\namespace.ilean -c E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\ir\\CML_Lean\\namespace.c --setup E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\ir\\CML_Lean\\namespace.setup.json --json\n",
      "error: CML_Lean/namespace.lean:54:0: (kernel) arg #5 of 'CML_Lean.namespace.cml_namespace.mk' contains a non valid occurrence of the datatypes being declared\n",
      "warning: CML_Lean/namespace.lean:69:2: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "error: CML_Lean/namespace.lean:80:57: don't know how to synthesize implicit argument `v`\n",
      "  @nsLookupMod m (?m.39 env mn path x✝) (?m.40 env mn path x✝) inst✝ x✝ path\n",
      "context:\n",
      "m n v : Type\n",
      "inst✝ : DecidableEq m\n",
      "env : sorry\n",
      "mn : m\n",
      "path : List m\n",
      "x✝ : sorry\n",
      "⊢ Type\n",
      "error: CML_Lean/namespace.lean:80:57: don't know how to synthesize implicit argument `n`\n",
      "  @nsLookupMod m (?m.39 env mn path x✝) (?m.40 env mn path x✝) inst✝ x✝ path\n",
      "context:\n",
      "m n v : Type\n",
      "inst✝ : DecidableEq m\n",
      "env : sorry\n",
      "mn : m\n",
      "path : List m\n",
      "x✝ : sorry\n",
      "⊢ Type\n",
      "warning: CML_Lean/namespace.lean:79:2: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:86:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:86:13: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:86:15: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:86:17: unused variable `v`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:92:14: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:16: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:18: unused variable `v`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:29: unused variable `ns1`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:33: unused variable `ns2`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:99:14: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:16: unused variable `v`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:27: unused variable `mn`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:36: unused variable `env`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:106:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:106:17: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:106:32: unused variable `a`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "error: CML_Lean/namespace.lean:114:2: `sorryAx` is not a structure\n",
      "error: CML_Lean/namespace.lean:121:31: don't know how to synthesize implicit argument `m`\n",
      "  @nsBind (?m.16 k val) n v k val acc\n",
      "context:\n",
      "m n v : Type\n",
      "l : List (n × v)\n",
      "e : sorry\n",
      "x✝ : n × v\n",
      "acc : sorry\n",
      "k : n\n",
      "val : v\n",
      "⊢ Type\n",
      "error: CML_Lean/namespace.lean:130:14: don't know how to synthesize implicit argument `m`\n",
      "  @nsBind (?m.21 n_opt x env k) n v k x env\n",
      "context:\n",
      "m n v : Type\n",
      "n_opt : Option n\n",
      "x : v\n",
      "env : sorry\n",
      "k : n\n",
      "⊢ Type\n",
      "warning: CML_Lean/namespace.lean:136:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:136:12: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:136:27: unused variable `k`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:136:35: unused variable `x`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "error: CML_Lean/namespace.lean:148:42: typeclass instance problem is stuck, it is often due to metavariables\n",
      "  DecidableEq ?m.36\n",
      "warning: CML_Lean/namespace.lean:154:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:162:4: declaration uses 'sorry'\n",
      "error: CML_Lean/namespace.lean:171:38: unexpected token '}'; expected '=>'\n",
      "error: CML_Lean/namespace.lean:170:87: Function expected at\n",
      "  Set\n",
      "but this term has type\n",
      "  ?m.1\n",
      "\n",
      "Note: Expected a function because this term is being applied to the argument\n",
      "  (cml_id n m)\n",
      "error: CML_Lean/namespace.lean:180:47: unexpected token '}'; expected '=>'\n",
      "error: CML_Lean/namespace.lean:179:74: Function expected at\n",
      "  Set\n",
      "but this term has type\n",
      "  ?m.1\n",
      "\n",
      "Note: Expected a function because this term is being applied to the argument\n",
      "  (List m)\n",
      "warning: CML_Lean/namespace.lean:187:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:187:11: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:187:13: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:187:28: unused variable `f`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "error: Lean exited with code 1\n",
      "⚠ [3/14] Built CML_Lean.location (953ms)\n",
      "warning: CML_Lean/location.lean:95:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:101:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:107:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:113:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:119:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:125:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:137:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:143:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:149:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:168:10: unused variable `h2`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/location.lean:185:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:192:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:200:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:207:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:213:8: declaration uses 'sorry'\n",
      "✔ [13/14] Built CML_Lean.location:c.o (254ms)\n",
      "Some required targets logged failures:\n",
      "- CML_Lean.namespace\n",
      "\n",
      "\n",
      "STDERR:\n",
      "error: build failed\n",
      "\n",
      "\n",
      "✗ Build failed with exit code 1\n",
      "STDOUT:\n",
      "✖ [2/14] Building CML_Lean.namespace (927ms)\n",
      "trace: .> LEAN_PATH=E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\lib\\lean c:\\Users\\my-pc\\.elan\\toolchains\\leanprover--lean4---v4.25.2\\bin\\lean.exe E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\CML_Lean\\namespace.lean -o E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\lib\\lean\\CML_Lean\\namespace.olean -i E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\lib\\lean\\CML_Lean\\namespace.ilean -c E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\ir\\CML_Lean\\namespace.c --setup E:\\NUS\\mcomp\\Dissertation\\CakeML_data_extraction\\extracted\\CML_Lean\\.lake\\build\\ir\\CML_Lean\\namespace.setup.json --json\n",
      "error: CML_Lean/namespace.lean:54:0: (kernel) arg #5 of 'CML_Lean.namespace.cml_namespace.mk' contains a non valid occurrence of the datatypes being declared\n",
      "warning: CML_Lean/namespace.lean:69:2: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:68:4: declaration uses 'sorry'\n",
      "error: CML_Lean/namespace.lean:80:57: don't know how to synthesize implicit argument `v`\n",
      "  @nsLookupMod m (?m.39 env mn path x✝) (?m.40 env mn path x✝) inst✝ x✝ path\n",
      "context:\n",
      "m n v : Type\n",
      "inst✝ : DecidableEq m\n",
      "env : sorry\n",
      "mn : m\n",
      "path : List m\n",
      "x✝ : sorry\n",
      "⊢ Type\n",
      "error: CML_Lean/namespace.lean:80:57: don't know how to synthesize implicit argument `n`\n",
      "  @nsLookupMod m (?m.39 env mn path x✝) (?m.40 env mn path x✝) inst✝ x✝ path\n",
      "context:\n",
      "m n v : Type\n",
      "inst✝ : DecidableEq m\n",
      "env : sorry\n",
      "mn : m\n",
      "path : List m\n",
      "x✝ : sorry\n",
      "⊢ Type\n",
      "warning: CML_Lean/namespace.lean:79:2: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:86:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:86:13: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:86:15: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:86:17: unused variable `v`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:92:14: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:16: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:18: unused variable `v`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:29: unused variable `ns1`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:92:33: unused variable `ns2`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:99:14: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:16: unused variable `v`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:27: unused variable `mn`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:99:36: unused variable `env`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:106:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:106:17: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:106:32: unused variable `a`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "error: CML_Lean/namespace.lean:114:2: `sorryAx` is not a structure\n",
      "error: CML_Lean/namespace.lean:121:31: don't know how to synthesize implicit argument `m`\n",
      "  @nsBind (?m.16 k val) n v k val acc\n",
      "context:\n",
      "m n v : Type\n",
      "l : List (n × v)\n",
      "e : sorry\n",
      "x✝ : n × v\n",
      "acc : sorry\n",
      "k : n\n",
      "val : v\n",
      "⊢ Type\n",
      "error: CML_Lean/namespace.lean:130:14: don't know how to synthesize implicit argument `m`\n",
      "  @nsBind (?m.21 n_opt x env k) n v k x env\n",
      "context:\n",
      "m n v : Type\n",
      "n_opt : Option n\n",
      "x : v\n",
      "env : sorry\n",
      "k : n\n",
      "⊢ Type\n",
      "warning: CML_Lean/namespace.lean:136:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:136:12: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:136:27: unused variable `k`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:136:35: unused variable `x`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "error: CML_Lean/namespace.lean:148:42: typeclass instance problem is stuck, it is often due to metavariables\n",
      "  DecidableEq ?m.36\n",
      "warning: CML_Lean/namespace.lean:154:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:162:4: declaration uses 'sorry'\n",
      "error: CML_Lean/namespace.lean:171:38: unexpected token '}'; expected '=>'\n",
      "error: CML_Lean/namespace.lean:170:87: Function expected at\n",
      "  Set\n",
      "but this term has type\n",
      "  ?m.1\n",
      "\n",
      "Note: Expected a function because this term is being applied to the argument\n",
      "  (cml_id n m)\n",
      "error: CML_Lean/namespace.lean:180:47: unexpected token '}'; expected '=>'\n",
      "error: CML_Lean/namespace.lean:179:74: Function expected at\n",
      "  Set\n",
      "but this term has type\n",
      "  ?m.1\n",
      "\n",
      "Note: Expected a function because this term is being applied to the argument\n",
      "  (List m)\n",
      "warning: CML_Lean/namespace.lean:187:4: declaration uses 'sorry'\n",
      "warning: CML_Lean/namespace.lean:187:11: unused variable `m`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:187:13: unused variable `n`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/namespace.lean:187:28: unused variable `f`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "error: Lean exited with code 1\n",
      "⚠ [3/14] Built CML_Lean.location (953ms)\n",
      "warning: CML_Lean/location.lean:95:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:101:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:107:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:113:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:119:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:125:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:137:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:143:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:149:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:168:10: unused variable `h2`\n",
      "\n",
      "Note: This linter can be disabled with `set_option linter.unusedVariables false`\n",
      "warning: CML_Lean/location.lean:185:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:192:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:200:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:207:8: declaration uses 'sorry'\n",
      "warning: CML_Lean/location.lean:213:8: declaration uses 'sorry'\n",
      "✔ [13/14] Built CML_Lean.location:c.o (254ms)\n",
      "Some required targets logged failures:\n",
      "- CML_Lean.namespace\n",
      "\n",
      "\n",
      "STDERR:\n",
      "error: build failed\n",
      "\n",
      "\n",
      "✗ Build failed with exit code 1\n"
     ]
    }
   ],
   "source": [
    "# Build the LEAN package\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"Building LEAN package...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Change to the package directory and run lake build\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"lake\", \"build\"],\n",
    "        cwd=LEAN_PROJECT_DIR,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=300  # 5 minute timeout\n",
    "    )\n",
    "    \n",
    "    print(\"STDOUT:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"\\nSTDERR:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n✓ Package built successfully!\")\n",
    "        print(\"\\nTo work with these LEAN files:\")\n",
    "        print(f\"1. Open '{LEAN_PROJECT_DIR}' folder in VS Code\")\n",
    "        print(\"2. The LEAN extension will recognize the package\")\n",
    "        print(\"3. Imports like 'import CML_Lean.namespace' will work\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Build failed with exit code {result.returncode}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'lake' command not found!\")\n",
    "    print(\"\\nYou need to install LEAN 4 first:\")\n",
    "    print(\"  Visit: https://lean-lang.org/lean4/doc/setup.html\")\n",
    "    print(\"\\nOr run manually in terminal:\")\n",
    "    print(f\"  cd {LEAN_PROJECT_DIR}\")\n",
    "    print(\"  lake build\")\n",
    "    \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"ERROR: Build timed out after 5 minutes\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa382d6c",
   "metadata": {},
   "source": [
    "## Initialize Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2364ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "\n",
    "# Initialize chat for maintaining conversation context across files\n",
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10586281",
   "metadata": {},
   "source": [
    "## Translation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea346883",
   "metadata": {},
   "source": [
    "### Translation Strategy\n",
    "\n",
    "This notebook uses a **sequential file translation approach with conversation context**:\n",
    "\n",
    "1. **Ordered Processing**: Files are processed in dependency order:\n",
    "   - locationScript.json (HOL4 base script)\n",
    "   - namespaceScript.json (base definitions)\n",
    "   - astScript.json (may depend on namespace)\n",
    "   - namespacePropsScript.json (theorems about namespace)\n",
    "\n",
    "1. **Conversation Context**: Uses Gemini's chat API to maintain context across files, so later translations can reference earlier ones.\n",
    "\n",
    "2. **Dependency Awareness**: The LLM remembers previous translations, ensuring consistent naming and type usage across files.\n",
    "\n",
    "3. **Type Consistency**: When translating theorems that reference datatypes or definitions from previous files, the LLM can recall how those were translated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34c5108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file_with_context(data: List[Dict], file_name: str, is_first: bool = False) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Translate HOL4 statements to LEAN using chat context.\n",
    "    \n",
    "    Args:\n",
    "        data: List of dictionaries with 'kind', 'name', 'statement', 'theory', 'ancestors' fields\n",
    "        file_name: Name of the file being translated\n",
    "        is_first: Whether this is the first file (sets up initial context)\n",
    "    \n",
    "    Returns:\n",
    "        List of translated items with LEAN statements\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get theory and ancestors info\n",
    "    theory = data[0]['theory'] if data else 'unknown'\n",
    "    ancestors = data[0]['ancestors'] if data else []\n",
    "    \n",
    "    # Build the prompt with all statements\n",
    "    if is_first:\n",
    "        prompt = f\"\"\"You are an expert in formal theorem proving systems. I will be translating multiple HOL4 theory files to LEAN 4 syntax. Please maintain context across our conversation as later files may reference definitions from earlier ones.\n",
    "\n",
    "Starting with file: {file_name}\n",
    "Theory: {theory}\n",
    "Ancestors: {ancestors}\n",
    "\n",
    "Translate ALL of the following HOL4 statements to LEAN 4 syntax.\n",
    "\n",
    "Instructions:\n",
    "- Use LEAN 4 syntax (not LEAN 3)\n",
    "- Preserve the logical structure and meaning\n",
    "- Use appropriate LEAN type annotations\n",
    "- Handle option types (SOME/NONE in HOL4 → some/none in LEAN)\n",
    "- Convert HOL4 list notation to LEAN list notation\n",
    "- Use LEAN's unicode symbols where appropriate (e.g., ∀, ∃, →, ∧, ∨)\n",
    "- Later statements may reference the previous ones.\n",
    "- This theory's ancestors are: {ancestors}. If any of these ancestors have been translated in our conversation, you may reference their definitions, types, and functions in your translation.\n",
    "\n",
    "CRITICAL - Reserved Keywords:\n",
    "- LEAN 4 has reserved keywords. If a HOL4 variable name matches a LEAN reserved keyword, append a \"cml_\" before it\n",
    "- Examples: 'id' becomes 'cml_id', 'namespace' becomes 'cml_namespace', etc.\n",
    "\n",
    "CRITICAL - Function Usage:\n",
    "- ONLY use functions that are predefined in LEAN 4 standard library or Mathlib\n",
    "- Common safe functions: List.map, List.filter, List.length, Option.map, Nat.add, etc.\n",
    "- DO NOT assume functions exist - verify they are in LEAN 4 stdlib\n",
    "\n",
    "Format your response as a JSON array where each element has:\n",
    "{{\n",
    "  \"name\": \"original_name\",\n",
    "  \"statement\": \"translated LEAN 4 statement\"\n",
    "}}\n",
    "\n",
    "Here are the HOL4 statements to translate:\n",
    "\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Now translating the next file: {file_name}\n",
    "Theory: {theory}\n",
    "Ancestors: {ancestors}\n",
    "\n",
    "IMPORTANT - Ancestor Dependencies:\n",
    "This theory depends on the following ancestors: {ancestors}\n",
    "- Some of these ancestors may have been translated in our previous conversation\n",
    "- When translating this file, you SHOULD reference types, datatypes, definitions, and functions from those ancestor theories\n",
    "- Use the SAME names and type signatures that you used when translating the ancestor files\n",
    "- Maintain consistency with all previous translations\n",
    "\n",
    "This file may also reference types and definitions from other previously translated files. Please use the SAME translated names and types from our earlier conversation.\n",
    "\n",
    "Translate ALL of the following HOL4 statements to LEAN 4 syntax, maintaining consistency with previous translations and utilizing definitions from ancestor theories:\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    # Add all statements to the prompt\n",
    "    for i, item in enumerate(data, 1):\n",
    "        prompt += f\"\\n{i}. {item['kind']}: {item['name']}\\n\"\n",
    "        prompt += f\"   HOL4 Statement:\\n   {item['statement']}\\n\"\n",
    "    \n",
    "    prompt += \"\\n\\nPlease provide the translations as a JSON array. Include ONLY the JSON array in your response, no additional text or markdown.\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Sending {len(data)} statements from {file_name} to LLM for translation...\")\n",
    "        response = chat.send_message(prompt)\n",
    "        response_text = response.text.strip()\n",
    "        \n",
    "        # Clean up markdown formatting if present\n",
    "        if response_text.startswith(\"```json\"):\n",
    "            response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "        elif response_text.startswith(\"```\"):\n",
    "            lines = response_text.split(\"\\n\")\n",
    "            response_text = \"\\n\".join(lines[1:-1]).strip()\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        translated_items = json.loads(response_text)\n",
    "        \n",
    "        # Match translations back to original items\n",
    "        name_to_translation = {item['name']: item['statement'] for item in translated_items}\n",
    "        \n",
    "        result = []\n",
    "        for item in data:\n",
    "            lean_statement = name_to_translation.get(item['name'], f\"[Translation not found for {item['name']}]\")\n",
    "            translated_item = {\n",
    "                \"kind\": item['kind'],\n",
    "                \"name\": item['name'],\n",
    "                \"statement\": lean_statement,\n",
    "                \"original_hol4\": item['statement'],\n",
    "                \"theory\": item.get('theory'),\n",
    "                \"ancestors\": item.get('ancestors', [])\n",
    "            }\n",
    "            result.append(translated_item)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON response: {str(e)}\")\n",
    "        print(f\"Response text: {response_text[:500]}...\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error during translation: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78c67101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_multiple_files(input_files: List[str], output_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Translate multiple JSON files in order, maintaining conversation context.\n",
    "    \n",
    "    Args:\n",
    "        input_files: List of input JSON file paths in dependency order\n",
    "        output_dir: Directory to save output files\n",
    "    \"\"\"\n",
    "    \n",
    "    all_results = {}\n",
    "    \n",
    "    for i, input_path in enumerate(input_files):\n",
    "        is_first = (i == 0)\n",
    "        file_name = input_path.split('/')[-1]\n",
    "        \n",
    "        # Load the input JSON file\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing file {i+1}/{len(input_files)}: {file_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"Loaded {len(data)} items\")\n",
    "        print(f\"  Types: {sum(1 for x in data if x['kind'] == 'Type')}\")\n",
    "        print(f\"  Datatypes: {sum(1 for x in data if x['kind'] == 'Datatype')}\")\n",
    "        print(f\"  Definitions: {sum(1 for x in data if x['kind'] == 'Definition')}\")\n",
    "        print(f\"  Theorems: {sum(1 for x in data if x['kind'] == 'Theorem')}\")\n",
    "        \n",
    "        # Translate with context\n",
    "        translated_data = translate_file_with_context(data, file_name, is_first)\n",
    "        \n",
    "        # Save individual output file\n",
    "        output_path = f\"{output_dir}/output_{file_name}\"\n",
    "        print(f\"Saving translated data to: {output_path}\")\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(translated_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        all_results[file_name] = translated_data\n",
    "        print(f\"✓ Completed {file_name}: {len(translated_data)} items translated\")\n",
    "        \n",
    "        # Small delay between files\n",
    "        if i < len(input_files) - 1:\n",
    "            print(\"\\nWaiting 2 seconds before next file...\")\n",
    "            time.sleep(2)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"All translations complete!\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total files processed: {len(input_files)}\")\n",
    "    print(f\"Total items translated: {sum(len(results) for results in all_results.values())}\")\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4c972",
   "metadata": {},
   "source": [
    "## Test Translation on First File\n",
    "\n",
    "Let's test the translation on the first file (namespaceScript.json):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641282e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing translation on: extracted/locationScript.json\n",
      "Loaded 28 items\n",
      "  Types: 0\n",
      "  Datatypes: 2\n",
      "  Definitions: 12\n",
      "  Theorems: 14\n",
      "\n",
      "Testing translation on first 5 items...\n",
      "Sending 5 statements from locationScript.json to LLM for translation...\n",
      "\n",
      "Translation Results:\n",
      "================================================================================\n",
      "\n",
      "Datatype: locn\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locn = UNKNOWNpt | EOFpt | POSN num num\n",
      "LEAN: inductive Locn where\n",
      "  | unknownpt\n",
      "  | eofpt\n",
      "  | posn (row : Nat) (col : Nat)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locnrow_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locnrow (POSN r c) = r\n",
      "LEAN: def locnrow (l : Locn) : Nat :=\n",
      "  match l with\n",
      "  | .posn r _ => r\n",
      "  | _ => 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locn_rowupdate_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locn_rowupdate f (POSN r c) = POSN (f r) c\n",
      "LEAN: def locn_rowupdate (f : Nat → Nat) (l : Locn) : Locn :=\n",
      "  match l with\n",
      "  | .posn r c => .posn (f r) ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locncol_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locncol (POSN r c) = c\n",
      "LEAN: def locncol (l : Locn) : Nat :=\n",
      "  match l with\n",
      "  | .posn _ c => c\n",
      "  | _ => 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locn_colupdate_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locn_colupdate f (POSN r c) = POSN r (f c)\n",
      "LEAN: def locn_colupdate (f : Nat → Nat) (l : Locn) : Locn :=\n",
      "  match l with\n",
      "  | .posn r c => .posn r (f c...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Translation Results:\n",
      "================================================================================\n",
      "\n",
      "Datatype: locn\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locn = UNKNOWNpt | EOFpt | POSN num num\n",
      "LEAN: inductive Locn where\n",
      "  | unknownpt\n",
      "  | eofpt\n",
      "  | posn (row : Nat) (col : Nat)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locnrow_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locnrow (POSN r c) = r\n",
      "LEAN: def locnrow (l : Locn) : Nat :=\n",
      "  match l with\n",
      "  | .posn r _ => r\n",
      "  | _ => 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locn_rowupdate_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locn_rowupdate f (POSN r c) = POSN (f r) c\n",
      "LEAN: def locn_rowupdate (f : Nat → Nat) (l : Locn) : Locn :=\n",
      "  match l with\n",
      "  | .posn r c => .posn (f r) ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locncol_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locncol (POSN r c) = c\n",
      "LEAN: def locncol (l : Locn) : Nat :=\n",
      "  match l with\n",
      "  | .posn _ c => c\n",
      "  | _ => 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Definition: locn_colupdate_def\n",
      "Theory: location, Ancestors: []\n",
      "HOL4: locn_colupdate f (POSN r c) = POSN r (f c)\n",
      "LEAN: def locn_colupdate (f : Nat → Nat) (l : Locn) : Locn :=\n",
      "  match l with\n",
      "  | .posn r c => .posn r (f c...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test on first file only\n",
    "test_file = INPUT_FILES[0]\n",
    "print(f\"Testing translation on: {test_file}\")\n",
    "\n",
    "with open(test_file, 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(test_data)} items\")\n",
    "print(f\"  Types: {sum(1 for x in test_data if x['kind'] == 'Type')}\")\n",
    "print(f\"  Datatypes: {sum(1 for x in test_data if x['kind'] == 'Datatype')}\")\n",
    "print(f\"  Definitions: {sum(1 for x in test_data if x['kind'] == 'Definition')}\")\n",
    "print(f\"  Theorems: {sum(1 for x in test_data if x['kind'] == 'Theorem')}\")\n",
    "\n",
    "# Test translation on a small subset (first 5 items)\n",
    "test_sample = test_data[:5]\n",
    "print(f\"\\nTesting translation on first {len(test_sample)} items...\")\n",
    "\n",
    "# Reset chat for testing\n",
    "chat = model.start_chat(history=[])\n",
    "translated_sample = translate_file_with_context(test_sample, test_file.split('/')[-1], is_first=True)\n",
    "\n",
    "print(f\"\\nTranslation Results:\")\n",
    "print(\"=\"*80)\n",
    "for item in translated_sample:\n",
    "    print(f\"\\n{item['kind']}: {item['name']}\")\n",
    "    print(f\"Theory: {item['theory']}, Ancestors: {item['ancestors']}\")\n",
    "    print(f\"HOL4: {item['original_hol4'][:100]}...\" if len(item['original_hol4']) > 100 else f\"HOL4: {item['original_hol4']}\")\n",
    "    print(f\"LEAN: {item['statement'][:100]}...\" if len(item['statement']) > 100 else f\"LEAN: {item['statement']}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e90995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential translation with context...\n",
      "\n",
      "================================================================================\n",
      "Processing file 1/4: locationScript.json\n",
      "================================================================================\n",
      "Loaded 28 items\n",
      "  Types: 0\n",
      "  Datatypes: 2\n",
      "  Definitions: 12\n",
      "  Theorems: 14\n",
      "Sending 28 statements from locationScript.json to LLM for translation...\n",
      "Saving translated data to: extracted/output_locationScript.json\n",
      "✓ Completed locationScript.json: 28 items translated\n",
      "\n",
      "Waiting 2 seconds before next file...\n",
      "Saving translated data to: extracted/output_locationScript.json\n",
      "✓ Completed locationScript.json: 28 items translated\n",
      "\n",
      "Waiting 2 seconds before next file...\n",
      "\n",
      "================================================================================\n",
      "Processing file 2/4: namespaceScript.json\n",
      "================================================================================\n",
      "Loaded 22 items\n",
      "  Types: 1\n",
      "  Datatypes: 2\n",
      "  Definitions: 19\n",
      "  Theorems: 0\n",
      "Sending 22 statements from namespaceScript.json to LLM for translation...\n",
      "\n",
      "================================================================================\n",
      "Processing file 2/4: namespaceScript.json\n",
      "================================================================================\n",
      "Loaded 22 items\n",
      "  Types: 1\n",
      "  Datatypes: 2\n",
      "  Definitions: 19\n",
      "  Theorems: 0\n",
      "Sending 22 statements from namespaceScript.json to LLM for translation...\n",
      "Saving translated data to: extracted/output_namespaceScript.json\n",
      "✓ Completed namespaceScript.json: 22 items translated\n",
      "\n",
      "Waiting 2 seconds before next file...\n",
      "Saving translated data to: extracted/output_namespaceScript.json\n",
      "✓ Completed namespaceScript.json: 22 items translated\n",
      "\n",
      "Waiting 2 seconds before next file...\n",
      "\n",
      "================================================================================\n",
      "Processing file 3/4: astScript.json\n",
      "================================================================================\n",
      "Loaded 30 items\n",
      "  Types: 4\n",
      "  Datatypes: 19\n",
      "  Definitions: 7\n",
      "  Theorems: 0\n",
      "Sending 30 statements from astScript.json to LLM for translation...\n",
      "\n",
      "================================================================================\n",
      "Processing file 3/4: astScript.json\n",
      "================================================================================\n",
      "Loaded 30 items\n",
      "  Types: 4\n",
      "  Datatypes: 19\n",
      "  Definitions: 7\n",
      "  Theorems: 0\n",
      "Sending 30 statements from astScript.json to LLM for translation...\n",
      "Saving translated data to: extracted/output_astScript.json\n",
      "✓ Completed astScript.json: 30 items translated\n",
      "\n",
      "Waiting 2 seconds before next file...\n",
      "Saving translated data to: extracted/output_astScript.json\n",
      "✓ Completed astScript.json: 30 items translated\n",
      "\n",
      "Waiting 2 seconds before next file...\n",
      "\n",
      "================================================================================\n",
      "Processing file 4/4: namespacePropsScript.json\n",
      "================================================================================\n",
      "Loaded 100 items\n",
      "  Types: 0\n",
      "  Datatypes: 0\n",
      "  Definitions: 3\n",
      "  Theorems: 97\n",
      "Sending 100 statements from namespacePropsScript.json to LLM for translation...\n",
      "\n",
      "================================================================================\n",
      "Processing file 4/4: namespacePropsScript.json\n",
      "================================================================================\n",
      "Loaded 100 items\n",
      "  Types: 0\n",
      "  Datatypes: 0\n",
      "  Definitions: 3\n",
      "  Theorems: 97\n",
      "Sending 100 statements from namespacePropsScript.json to LLM for translation...\n",
      "Saving translated data to: extracted/output_namespacePropsScript.json\n",
      "✓ Completed namespacePropsScript.json: 100 items translated\n",
      "\n",
      "================================================================================\n",
      "All translations complete!\n",
      "================================================================================\n",
      "Total files processed: 4\n",
      "Total items translated: 180\n",
      "\n",
      "================================================================================\n",
      "Translation completed successfully!\n",
      "================================================================================\n",
      "Saving translated data to: extracted/output_namespacePropsScript.json\n",
      "✓ Completed namespacePropsScript.json: 100 items translated\n",
      "\n",
      "================================================================================\n",
      "All translations complete!\n",
      "================================================================================\n",
      "Total files processed: 4\n",
      "Total items translated: 180\n",
      "\n",
      "================================================================================\n",
      "Translation completed successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "## Run Full Translation on All Files\n",
    "\n",
    "# Reset chat to start fresh\n",
    "chat = model.start_chat(history=[])\n",
    "\n",
    "print(\"Starting sequential translation with context...\")\n",
    "results = translate_multiple_files(INPUT_FILES, OUTPUT_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Translation completed successfully!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634b4ea",
   "metadata": {},
   "source": [
    "## Export Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b958c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Statistics by File:\n",
      "================================================================================\n",
      "\n",
      "locationScript.json:\n",
      "  Total items: 28\n",
      "  Types: 0\n",
      "  Datatypes: 2\n",
      "  Definitions: 12\n",
      "  Theorems: 14\n",
      "  Theory: location\n",
      "\n",
      "namespaceScript.json:\n",
      "  Total items: 22\n",
      "  Types: 1\n",
      "  Datatypes: 2\n",
      "  Definitions: 19\n",
      "  Theorems: 0\n",
      "  Theory: namespace\n",
      "\n",
      "astScript.json:\n",
      "  Total items: 30\n",
      "  Types: 4\n",
      "  Datatypes: 19\n",
      "  Definitions: 7\n",
      "  Theorems: 0\n",
      "  Theory: ast\n",
      "\n",
      "namespacePropsScript.json:\n",
      "  Total items: 100\n",
      "  Types: 0\n",
      "  Datatypes: 0\n",
      "  Definitions: 3\n",
      "  Theorems: 97\n",
      "  Theory: namespaceProps\n",
      "\n",
      "================================================================================\n",
      "Grand Total: 180 items translated across 4 files\n"
     ]
    }
   ],
   "source": [
    "# Generate statistics about the translations\n",
    "print(\"Translation Statistics by File:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_items = 0\n",
    "for input_file in INPUT_FILES:\n",
    "    file_name = input_file.split('/')[-1]\n",
    "    output_file = f\"{OUTPUT_DIR}/output_{file_name}\"\n",
    "    \n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            translated_data = json.load(f)\n",
    "        \n",
    "        print(f\"\\n{file_name}:\")\n",
    "        print(f\"  Total items: {len(translated_data)}\")\n",
    "        print(f\"  Types: {sum(1 for x in translated_data if x['kind'] == 'Type')}\")\n",
    "        print(f\"  Datatypes: {sum(1 for x in translated_data if x['kind'] == 'Datatype')}\")\n",
    "        print(f\"  Definitions: {sum(1 for x in translated_data if x['kind'] == 'Definition')}\")\n",
    "        print(f\"  Theorems: {sum(1 for x in translated_data if x['kind'] == 'Theorem')}\")\n",
    "        print(f\"  Theory: {translated_data[0]['theory'] if translated_data else 'N/A'}\")\n",
    "        \n",
    "        total_items += len(translated_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n{file_name}: Output file not found\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Grand Total: {total_items} items translated across {len(INPUT_FILES)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9dc78a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate LEAN Files\n",
    "\n",
    "def create_lean_file_from_json(input_json_path: str, output_lean_path: str, ancestors: List[str] = None) -> None:\n",
    "    \"\"\"\n",
    "    Create a .lean file from the translated JSON data.\n",
    "    \n",
    "    Args:\n",
    "        input_json_path: Path to the translated JSON file\n",
    "        output_lean_path: Path to the output .lean file\n",
    "        ancestors: List of ancestor theory names to import\n",
    "    \"\"\"\n",
    "    with open(input_json_path, 'r', encoding='utf-8') as f:\n",
    "        translated_data = json.load(f)\n",
    "    \n",
    "    theory_name = translated_data[0]['theory'] if translated_data else 'Unknown'\n",
    "    ancestors = ancestors or (translated_data[0].get('ancestors', []) if translated_data else [])\n",
    "    \n",
    "    # Get list of all translated theory files in the package\n",
    "    import os\n",
    "    available_theories = set()\n",
    "    if os.path.exists(LEAN_SOURCE_DIR):\n",
    "        for filename in os.listdir(LEAN_SOURCE_DIR):\n",
    "            if filename.endswith('.lean'):\n",
    "                theory = filename.replace('Script.lean', '').replace('.lean', '')\n",
    "                available_theories.add(theory)\n",
    "    \n",
    "    # Filter ancestors to only include those we have translated\n",
    "    valid_ancestors = [a for a in ancestors if a in available_theories]\n",
    "    \n",
    "    with open(output_lean_path, 'w', encoding='utf-8') as f:\n",
    "        # Write file header\n",
    "        f.write(f\"-- Auto-generated LEAN 4 file from HOL4 translation\\n\")\n",
    "        f.write(f\"-- Theory: {theory_name}\\n\")\n",
    "        f.write(f\"-- Generated using Gemini API\\n\\n\")\n",
    "        \n",
    "        # Import ancestor files if they exist and have been translated\n",
    "        if valid_ancestors:\n",
    "            f.write(f\"-- Import ancestor theories\\n\")\n",
    "            for ancestor in valid_ancestors:\n",
    "                # Use CML_Lean module prefix for imports\n",
    "                f.write(f\"import CML_Lean.{ancestor}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # Open namespace for this theory\n",
    "        f.write(f\"namespace CML_Lean.{theory_name}\\n\\n\")\n",
    "        \n",
    "        # Process each item\n",
    "        for item in translated_data:\n",
    "            kind = item['kind']\n",
    "            name = item['name']\n",
    "            statement = item['statement']\n",
    "            \n",
    "            # Add a block comment with the original HOL4 statement\n",
    "            f.write(f\"/-\\n\")\n",
    "            f.write(f\"Original HOL4 {kind}: {name}\\n\")\n",
    "            f.write(f\"{item['original_hol4']}\\n\")\n",
    "            f.write(f\"-/\\n\")\n",
    "            \n",
    "            if kind == \"Type\":\n",
    "                # Write type as-is\n",
    "                f.write(f\"{statement}\\n\\n\")\n",
    "                \n",
    "            elif kind == \"Datatype\":\n",
    "                # Write datatype as-is\n",
    "                f.write(f\"{statement}\\n\\n\")\n",
    "                \n",
    "            elif kind == \"Definition\":\n",
    "                # Write definition as-is\n",
    "                f.write(f\"{statement}\\n\\n\")\n",
    "                \n",
    "            elif kind == \"Theorem\":\n",
    "                # Format theorem with := by sorry for tactic-mode proving\n",
    "                # Check if statement already has a proof placeholder\n",
    "                statement_stripped = statement.strip()\n",
    "                if statement_stripped.endswith(\":= by sorry\") or statement_stripped.endswith(\":= sorry\"):\n",
    "                    # Already has a proof placeholder, use as-is\n",
    "                    f.write(f\"{statement}\\n\\n\")\n",
    "                elif statement.startswith(\"theorem \"):\n",
    "                    # Statement starts with \"theorem\", append := by sorry\n",
    "                    f.write(f\"{statement} := by sorry\\n\\n\")\n",
    "                else:\n",
    "                    # Need to add \"theorem\" keyword and proof placeholder\n",
    "                    f.write(f\"theorem {name} : {statement} := by sorry\\n\\n\")\n",
    "        \n",
    "        # Close namespace\n",
    "        f.write(f\"end CML_Lean.{theory_name}\\n\")\n",
    "    \n",
    "    print(f\"LEAN file created: {output_lean_path}\")\n",
    "    \n",
    "    # Print statistics\n",
    "    types = sum(1 for x in translated_data if x['kind'] == 'Type')\n",
    "    datatypes = sum(1 for x in translated_data if x['kind'] == 'Datatype')\n",
    "    definitions = sum(1 for x in translated_data if x['kind'] == 'Definition')\n",
    "    theorems = sum(1 for x in translated_data if x['kind'] == 'Theorem')\n",
    "    \n",
    "    print(f\"Content summary:\")\n",
    "    print(f\"  - Theory: {theory_name}\")\n",
    "    print(f\"  - Valid ancestors (translated): {valid_ancestors}\")\n",
    "    if len(ancestors) > len(valid_ancestors):\n",
    "        skipped = [a for a in ancestors if a not in valid_ancestors]\n",
    "        print(f\"  - Skipped ancestors (not translated): {skipped}\")\n",
    "    print(f\"  - {types} Types\")\n",
    "    print(f\"  - {datatypes} Datatypes\")\n",
    "    print(f\"  - {definitions} Definitions\")\n",
    "    print(f\"  - {theorems} Theorems (with := sorry)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dcb56dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LEAN files from translated JSON files...\n",
      "================================================================================\n",
      "\n",
      "Processing: locationScript.json -> location.lean\n",
      "LEAN file created: extracted/CML_Lean/CML_Lean/location.lean\n",
      "Content summary:\n",
      "  - Theory: location\n",
      "  - Valid ancestors (translated): []\n",
      "  - 0 Types\n",
      "  - 2 Datatypes\n",
      "  - 12 Definitions\n",
      "  - 14 Theorems (with := sorry)\n",
      "\n",
      "Processing: namespaceScript.json -> namespace.lean\n",
      "LEAN file created: extracted/CML_Lean/CML_Lean/namespace.lean\n",
      "Content summary:\n",
      "  - Theory: namespace\n",
      "  - Valid ancestors (translated): []\n",
      "  - Skipped ancestors (not translated): ['alist']\n",
      "  - 1 Types\n",
      "  - 2 Datatypes\n",
      "  - 19 Definitions\n",
      "  - 0 Theorems (with := sorry)\n",
      "\n",
      "Processing: astScript.json -> ast.lean\n",
      "LEAN file created: extracted/CML_Lean/CML_Lean/ast.lean\n",
      "Content summary:\n",
      "  - Theory: ast\n",
      "  - Valid ancestors (translated): ['namespace', 'location']\n",
      "  - Skipped ancestors (not translated): ['integer', 'words', 'string']\n",
      "  - 4 Types\n",
      "  - 19 Datatypes\n",
      "  - 7 Definitions\n",
      "  - 0 Theorems (with := sorry)\n",
      "\n",
      "Processing: namespacePropsScript.json -> namespaceProps.lean\n",
      "LEAN file created: extracted/CML_Lean/CML_Lean/namespaceProps.lean\n",
      "Content summary:\n",
      "  - Theory: namespaceProps\n",
      "  - Valid ancestors (translated): ['ast', 'namespace']\n",
      "  - 0 Types\n",
      "  - 0 Datatypes\n",
      "  - 3 Definitions\n",
      "  - 97 Theorems (with := sorry)\n",
      "\n",
      "================================================================================\n",
      "All LEAN files generated in package structure!\n",
      "LEAN files location: extracted/CML_Lean/CML_Lean/\n"
     ]
    }
   ],
   "source": [
    "def create_all_lean_files(input_files: List[str], output_dir: str) -> None:\n",
    "    \"\"\"\n",
    "    Create LEAN files for all translated JSON files in the proper package structure.\n",
    "    \n",
    "    Args:\n",
    "        input_files: List of original input JSON file paths\n",
    "        output_dir: Directory containing the translated JSON files\n",
    "    \"\"\"\n",
    "    print(\"Generating LEAN files from translated JSON files...\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for input_file in input_files:\n",
    "        file_name = input_file.split('/')[-1]\n",
    "        \n",
    "        # Path to translated JSON\n",
    "        translated_json = f\"{output_dir}/output_{file_name}\"\n",
    "        \n",
    "        # Check if translated JSON exists\n",
    "        try:\n",
    "            with open(translated_json, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Get theory name from the data\n",
    "            theory_name = data[0]['theory'] if data else file_name.replace('.json', '')\n",
    "            ancestors = data[0].get('ancestors', []) if data else []\n",
    "            \n",
    "            # Path to output LEAN file using theory name\n",
    "            lean_output = f\"{LEAN_SOURCE_DIR}/{theory_name}.lean\"\n",
    "            \n",
    "            print(f\"\\nProcessing: {file_name} -> {theory_name}.lean\")\n",
    "            create_lean_file_from_json(translated_json, lean_output, ancestors)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"\\nWarning: Translated file not found: {translated_json}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"All LEAN files generated in package structure!\")\n",
    "    print(f\"LEAN files location: {LEAN_SOURCE_DIR}/\")\n",
    "\n",
    "# Generate LEAN files for all translated JSON files\n",
    "create_all_lean_files(INPUT_FILES, OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
